from typing import Optional

import numpy as np

from infsim.environments.base_simulator import PolicyLogs, BaseEnvironment


def create_buckets_from_scores(
    scores: np.array, n_buckets: int, max_relative_size: Optional[float] = None
) -> np.array:
    """
    Create buckets from a list of scores. Best effort is taken to create buckets of equal size, but if duplicate scores
    exist this cannot be guaranteed.

    If the number of buckets is more than the number of unique scores, an error is raised.
    If the biggest bucket is more than `max_relative_size` times the smallest bucket, an error is raised.

    :param scores: Numpy array containing all scores to be bucketized. Can be of any shape, buckets are _not_ created
                    along axis, but assigned to individual elements.
    :param n_buckets: Number of buckets to be created
    :param max_relative_size: (Optional) if provided, the biggest bucket is not allowed to be more
                than `max_relative_size` times the smallest bucket.
    :return: Returns numpy array of same size as scores with an integer id representing the assigned bucket.
    """
    if n_buckets > len(np.unique(scores)):
        raise RuntimeError("Less scores than number of specified buckets")

    percentiles = np.linspace(100, 0, n_buckets + 1)[1:-1]
    thresholds = np.percentile(scores, percentiles)

    buckets = np.digitize(scores, thresholds)

    if max_relative_size:
        _, counts = np.unique(buckets, return_counts=True)
        relative_size = np.max(counts) / np.min(counts)
        if relative_size > max_relative_size:
            raise RuntimeError(
                f"Relative bucket size exceeds threshold of {max_relative_size:.1f}x (biggest bucket is {relative_size:.1f}x larger than smallest bucket)"
            )

    return buckets


def compute_incremental_metrics(
    env: BaseEnvironment,
    logs: PolicyLogs,
    assigned_buckets: np.array,
    treatment_mask: np.array = None,
) -> dict:
    """
    This method computes a collection of ground-truth incremental metrics for a given set of treatment buckets.

    Note: A final bucket for treatment of all items is automatically added.

    The resulting dict contains the following metrics:
    - `expected_conversions`: The recommended conversion metric. This metric is computed using the conversion
            probabilities generated by the simulator, allowing for a low-variance estimate of the conversion.
    - `expected_profit`: The recommended profit/loss metric. This metric is computed using the conversion
            probabilities generated by the simulator combined with the known price and commission,
            allowing for a low-variance estimate of the profit.
    - `conversions`: This metric uses the realised conversions after sampling from the conversion probabilities in
            the simulator. Other than the `expected_conversions` metric, this value is not deterministic.
    - `profit`: - `conversions`: This metric uses the realised conversions after sampling from the conversion
            probabilities the simulator together with the real price and commission. Other than the
            `expected_profit` metric, this value is not deterministic.

    :param env: The simulator environment that was used to generate the logs and policy. This is use for resampling
            the metrics for each of the "thresholds" coming out of the buckets.
    :param logs: Logs to use for evaluating the assigned buckets. Does not need to contain treatments and model scores.
    :param assigned_buckets: A numpy array of the same length as logs.item_context that represents various model
            thresholds. For example, if model scores are [.2, .5, .6, .1] and we have a single threshold of .3, our
            buckets would be [1, 2, 2, 1].
    :param treatment_mask: (Optional) if provided, treatments are only assigned if the item is inside the bucket AND
            the treatment mask is 1. Some examples:
                Let assume we are looking at bucket 2.
                if item i,j is in bucket 1, but i,j is set to 0 in treatment mask item i,j will be not treatment.
                if item i,j is in bucket 1, but i,j is set to 1 in treatment mask item i,j will be treatment.
                if item i,j is in bucket 3, item i,j will be not treatment.
    :return: A dict containing a list of values for each of the defined metrics and each bucket.
    """
    metrics = {
        "expected_profit": np.array([]),
        "expected_conversions": np.array([]),
        "profit": np.array([]),
        "conversions": np.array([]),
        "_treatments": [],
    }
    _bucketized_logs = []

    buckets = sorted(np.unique(assigned_buckets))
    buckets += [max(buckets) + 1]  # Add one more bucket for treating everything
    for bucket in buckets:
        treatments = assigned_buckets < bucket
        if treatment_mask is not None:
            treatments = treatments * treatment_mask

        # For debugging purposes
        metrics["_treatments"].append(treatments)
        _treatment_logs = env.resample_with_alternative_policy(
            logs, treatment=treatments
        )

        metrics["expected_profit"] = np.append(
            metrics["expected_profit"], _treatment_logs.expected_profit.sum()
        )
        metrics["expected_conversions"] = np.append(
            metrics["expected_conversions"],
            _treatment_logs.user_context._conversion_probability.sum(),
        )
        metrics["profit"] = np.append(metrics["profit"], _treatment_logs.profit.sum())
        metrics["conversions"] = np.append(
            metrics["conversions"], _treatment_logs.item_context.is_converted.sum()
        )
        _bucketized_logs.append(_treatment_logs)

    metrics["expected_incr_profit"] = (
        metrics["expected_profit"] - metrics["expected_profit"][0]
    )
    metrics["expected_incr_conversions"] = (
        metrics["expected_conversions"] - metrics["expected_conversions"][0]
    )

    return metrics
